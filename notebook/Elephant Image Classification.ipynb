{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snapshot Serengeti Inception-V3\n",
    "\n",
    "## Disclaimer\n",
    "This uses the pre-built and open source inception v3 model as a baseline.\n",
    "For more information see https://www.tensorflow.org/tutorials/image_recognition#usage_with_python_api.\n",
    "You can also find the original source code that is modified here at https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Imports\n",
    "from IPython.display import Image\n",
    "\n",
    "# Basic Data Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Google Inception Imports\n",
    "from six.moves import urllib\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import re\n",
    "\n",
    "# African Elephant, Tusker, Indian Elephant\n",
    "elephant_nodes = {24, 214, 914}\n",
    "ELEPHANT_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Default codebase is vagrant\n",
    "# If you aren't using vagrant replace codebase with your personal\n",
    "# root.  For example, ~/home/projects/code-base\n",
    "CODEBASE_DIR = '/vagrant'\n",
    "\n",
    "# General Constants\n",
    "DATA_DIR = CODEBASE_DIR + '/data'\n",
    "MODEL_DIR = CODEBASE_DIR + '/models'\n",
    "\n",
    "# Google Constants\n",
    "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "DEST_DIRECTORY = MODEL_DIR +'/inceptionv3'\n",
    "NUM_TOP_PREDICTIONS = 5\n",
    "\n",
    "# Global State\n",
    "GRAPH_STARTED = False\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NodeLookup(object):\n",
    "  \"\"\"Converts integer node ID's to human readable labels.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               label_lookup_path=None,\n",
    "               uid_lookup_path=None):\n",
    "    if not label_lookup_path:\n",
    "      label_lookup_path = os.path.join(\n",
    "          DEST_DIRECTORY, 'imagenet_2012_challenge_label_map_proto.pbtxt')\n",
    "    if not uid_lookup_path:\n",
    "      uid_lookup_path = os.path.join(\n",
    "          DEST_DIRECTORY, 'imagenet_synset_to_human_label_map.txt')\n",
    "    self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "\n",
    "  def load(self, label_lookup_path, uid_lookup_path):\n",
    "    \"\"\"Loads a human readable English name for each softmax node.\n",
    "\n",
    "    Args:\n",
    "      label_lookup_path: string UID to integer node ID.\n",
    "      uid_lookup_path: string UID to human-readable string.\n",
    "\n",
    "    Returns:\n",
    "      dict from integer node ID to human-readable string.\n",
    "    \"\"\"\n",
    "    if not tf.gfile.Exists(uid_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', uid_lookup_path)\n",
    "    if not tf.gfile.Exists(label_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', label_lookup_path)\n",
    "\n",
    "    # Loads mapping from string UID to human-readable string\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "    uid_to_human = {}\n",
    "    p = re.compile(r'[n\\d]*[ \\S,]*')\n",
    "    for line in proto_as_ascii_lines:\n",
    "      parsed_items = p.findall(line)\n",
    "      uid = parsed_items[0]\n",
    "      human_string = parsed_items[2]\n",
    "      uid_to_human[uid] = human_string\n",
    "\n",
    "    # Loads mapping from string UID to integer node ID.\n",
    "    node_id_to_uid = {}\n",
    "    proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "    for line in proto_as_ascii:\n",
    "      if line.startswith('  target_class:'):\n",
    "        target_class = int(line.split(': ')[1])\n",
    "      if line.startswith('  target_class_string:'):\n",
    "        target_class_string = line.split(': ')[1]\n",
    "        node_id_to_uid[target_class] = target_class_string[1:-2]\n",
    "\n",
    "    # Loads the final mapping of integer node ID to human-readable string\n",
    "    node_id_to_name = {}\n",
    "    for key, val in node_id_to_uid.items():\n",
    "      if val not in uid_to_human:\n",
    "        tf.logging.fatal('Failed to locate: %s', val)\n",
    "      name = uid_to_human[val]\n",
    "      node_id_to_name[key] = name\n",
    "\n",
    "    return node_id_to_name\n",
    "\n",
    "  def id_to_string(self, node_id):\n",
    "    if node_id not in self.node_lookup:\n",
    "      return ''\n",
    "    return self.node_lookup[node_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download Google Incpetion v3 Model\n",
    "# Based on https://www.tensorflow.org/tutorials/image_recognition#usage_with_python_api\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "  \"\"\"Download and extract model tar file.\"\"\"\n",
    "  if not os.path.exists(DEST_DIRECTORY):\n",
    "    os.makedirs(DEST_DIRECTORY)\n",
    "  filename = DATA_URL.split('/')[-1]\n",
    "  filepath = os.path.join(DEST_DIRECTORY, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
    "          filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  tarfile.open(filepath, 'r:gz').extractall(DEST_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "  global GRAPH_STARTED\n",
    "  if GRAPH_STARTED:\n",
    "    return\n",
    "\n",
    "  GRAPH_STARTED = True\n",
    "  \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n",
    "  # Creates graph from saved graph_def.pb.\n",
    "  with tf.gfile.FastGFile(os.path.join(\n",
    "      DEST_DIRECTORY, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_inference_on_image(image):\n",
    "  \"\"\"Runs inference on an image.\n",
    "\n",
    "  Args:\n",
    "    image: Image file name.\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  if not tf.gfile.Exists(image):\n",
    "    tf.logging.fatal('File does not exist %s', image)\n",
    "  image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "\n",
    "  # Creates graph from saved GraphDef.\n",
    "  create_graph()\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    # Some useful tensors:\n",
    "    # 'softmax:0': A tensor containing the normalized prediction across\n",
    "    #   1000 labels.\n",
    "    # 'pool_3:0': A tensor containing the next-to-last layer containing 2048\n",
    "    #   float description of the image.\n",
    "    # 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG\n",
    "    #   encoding of the image.\n",
    "    # Runs the softmax tensor by feeding the image_data as input to the graph.\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "    predictions = sess.run(softmax_tensor,\n",
    "                           {'DecodeJpeg/contents:0': image_data})\n",
    "    predictions = np.squeeze(predictions)\n",
    "\n",
    "    # Creates node ID --> English string lookup.\n",
    "    node_lookup = NodeLookup()\n",
    "\n",
    "    top_k = predictions.argsort()[-NUM_TOP_PREDICTIONS:][::-1]\n",
    "    top_k_list = []\n",
    "    for node_id in top_k:\n",
    "      human_string = node_lookup.id_to_string(node_id)\n",
    "      score = predictions[node_id]\n",
    "      top_k_list.append((human_string, node_id, score))\n",
    "    \n",
    "    return top_k_list\n",
    "\n",
    "def run_elephant_inference(image):\n",
    "    top_k = run_inference_on_image(image)\n",
    "    is_elephant = 0\n",
    "    \n",
    "    for (human_string, node_id, score) in top_k:\n",
    "        if node_id in elephant_nodes:\n",
    "            is_elephant += score\n",
    "    \n",
    "    return is_elephant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run classification on snapshot data\n",
    "maybe_download_and_extract()\n",
    "elephant_dir = DATA_DIR + '/snapshot/Elephant'\n",
    "img_elephants = [os.path.join(elephant_dir, img) for img in os.listdir(elephant_dir)]\n",
    "\n",
    "imgs = np.random.randint(0, len(img_elephants), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random image exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_elephants[imgs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_elephants[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_elephants[imgs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_elephants[imgs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_elephants[imgs[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_elephants[imgs[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_elephants[imgs[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_elephants[imgs[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_elephants[imgs[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_elephants[imgs[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_download_and_extract()\n",
    "rhino_dir = DATA_DIR + '/snapshot/Rhino'\n",
    "img_rhinos = [os.path.join(rhino_dir, img) for img in os.listdir(rhino_dir)]\n",
    "\n",
    "imgs = np.random.randint(0, len(img_rhinos), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_rhinos[imgs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_rhinos[imgs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_rhinos[imgs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_rhinos[imgs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_rhinos[imgs[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_rhinos[imgs[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_rhinos[imgs[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_rhinos[imgs[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_rhinos[imgs[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_rhinos[imgs[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tapir_dir = DATA_DIR + '/tapir-single'\n",
    "img_tapir = [os.path.join(tapir_dir, img) for img in os.listdir(tapir_dir)]\n",
    "\n",
    "imgs = np.random.randint(0, len(img_tapir), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_tapir[imgs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_tapir[imgs[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference_on_image(img_tapir[imgs[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Inception Based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elephants\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Classification is slow, short-circuit\n",
    "result_cache  = \"classifications2.npy\"\n",
    "\n",
    "keep = np.random.choice((True,False), size=len(img_elephants), replace=True, p=(0.03, 0.97))\n",
    "kept_elephants = np.array(img_elephants)[keep]\n",
    "\n",
    "if os.path.exists(DATA_DIR + '/' + result_cache):\n",
    "    results = np.load(DATA_DIR + '/' + result_cache).item()\n",
    "    print(\"Read cache from %s\" % (DATA_DIR + '/' + result_cache))\n",
    "else:   \n",
    "    for i in range(len(kept_elephants)):\n",
    "        img = kept_elephants[i]\n",
    "        sys.stdout.write(\"\\r[%i%% DONE] Classifying %i of %i, img %s \" % (i/len(kept_elephants)*100 ,i, len(kept_elephants), img))\n",
    "        sys.stdout.flush()\n",
    "        result = run_inference_on_image(img)\n",
    "        for r in result:\n",
    "            typ, id, score = r\n",
    "            if typ not in results:\n",
    "                results[typ] = []\n",
    "            results[typ].append(score)\n",
    "\n",
    "    np.save(DATA_DIR + '/' + result_cache, results)\n",
    "    sys.stdout.write(\"\\r[100%% DONE] All Images Classified, results saved to %s\" % (DATA_DIR + '/' + result_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Weimaraner', 0.81148893),\n",
       " ('dugong, Dugong dugon', 0.54536313),\n",
       " ('window screen', 0.38485044),\n",
       " ('Band Aid', 0.30938321),\n",
       " ('hamster', 0.22231169),\n",
       " ('hog, pig, grunter, squealer, Sus scrofa', 0.20053299),\n",
       " ('baboon', 0.17032586),\n",
       " ('butternut squash', 0.10651258),\n",
       " ('tusker', 0.1012743),\n",
       " ('stingray', 0.098986946),\n",
       " ('coral reef', 0.091006801),\n",
       " ('water buffalo, water ox, Asiatic buffalo, Bubalus bubalis', 0.089154691),\n",
       " ('groenendael', 0.0889102),\n",
       " ('Indian elephant, Elephas maximus', 0.083813876),\n",
       " ('wild boar, boar, Sus scrofa', 0.069169536),\n",
       " ('wombat', 0.065326281),\n",
       " ('white wolf, Arctic wolf, Canis lupus tundrarum', 0.05831974),\n",
       " ('hay', 0.057172976),\n",
       " ('electric ray, crampfish, numbfish, torpedo', 0.055109512),\n",
       " ('Scottish deerhound, deerhound', 0.054729603),\n",
       " ('platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus',\n",
       "  0.054270171),\n",
       " ('Samoyed, Samoyede', 0.052275222),\n",
       " ('grey fox, gray fox, Urocyon cinereoargenteus', 0.051895089),\n",
       " ('Arctic fox, white fox, Alopex lagopus', 0.047765717),\n",
       " ('badger', 0.044895701),\n",
       " ('coyote, prairie wolf, brush wolf, Canis latrans', 0.044686347),\n",
       " ('armadillo', 0.042942591),\n",
       " ('ox', 0.042913184),\n",
       " ('screen, CRT screen', 0.042011127),\n",
       " ('American black bear, black bear, Ursus americanus, Euarctos americanus',\n",
       "  0.040270399),\n",
       " ('monitor', 0.039114378),\n",
       " ('sturgeon', 0.038524777),\n",
       " ('park bench', 0.038457911),\n",
       " ('quail', 0.037744176),\n",
       " ('red wolf, maned wolf, Canis rufus, Canis niger', 0.035987195),\n",
       " ('television, television system', 0.035709694),\n",
       " ('barn', 0.033988658),\n",
       " ('gorilla, Gorilla gorilla', 0.033132013),\n",
       " ('hammerhead, hammerhead shark', 0.032406021),\n",
       " ('timber wolf, grey wolf, gray wolf, Canis lupus', 0.031344905),\n",
       " ('African elephant, Loxodonta africana', 0.031137146),\n",
       " ('brown bear, bruin, Ursus arctos', 0.030667281),\n",
       " ('warthog', 0.029319109),\n",
       " ('skunk, polecat, wood pussy', 0.029039945),\n",
       " ('ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus', 0.027595203),\n",
       " ('hyena, hyaena', 0.027077755),\n",
       " ('dhole, Cuon alpinus', 0.026511649),\n",
       " ('fountain', 0.025981385),\n",
       " ('viaduct', 0.02597107),\n",
       " ('piggy bank, penny bank', 0.025760476),\n",
       " ('bathing cap, swimming cap', 0.0253148),\n",
       " ('sloth bear, Melursus ursinus, Ursus ursinus', 0.024565212),\n",
       " ('lighter, light, igniter, ignitor', 0.021232149),\n",
       " ('syringe', 0.019751271),\n",
       " ('web site, website, internet site, site', 0.019235598),\n",
       " ('Great Dane', 0.019103328),\n",
       " ('book jacket, dust cover, dust jacket, dust wrapper', 0.018305246),\n",
       " ('hippopotamus, hippo, river horse, Hippopotamus amphibius', 0.017769445),\n",
       " ('wallaby, brush kangaroo', 0.016137479),\n",
       " ('mouse, computer mouse', 0.013737981),\n",
       " ('red fox, Vulpes vulpes', 0.010769008),\n",
       " ('Irish wolfhound', 0.0056449892),\n",
       " ('tiger shark, Galeocerdo cuvieri', 0.0038236196),\n",
       " ('planetarium', 0.0018583817),\n",
       " ('wok', 0.001768116),\n",
       " ('bubble', 0.0017170836)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the top classes classified by median\n",
    "\n",
    "all_classes = []\n",
    "\n",
    "for key in results.keys():\n",
    "    median = np.median(results[key])\n",
    "    all_classes.append((key, median))\n",
    "\n",
    "sorted(all_classes, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top classes classified by average\n",
    "\n",
    "avg = []\n",
    "\n",
    "for key in results.keys():\n",
    "    av = np.average(results[key])\n",
    "    avg.append((key, av))\n",
    "    \n",
    "sorted(avg, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top classes classified by max\n",
    "\n",
    "maxi = []\n",
    "\n",
    "for key in results.keys():\n",
    "    m = np.max(results[key])\n",
    "    maxi.append((key, m))\n",
    "\n",
    "sorted(maxi, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top classes classified by total images classified\n",
    "\n",
    "total = []\n",
    "\n",
    "for key in results.keys():\n",
    "    m = len(results[key])\n",
    "    total.append((key, m))\n",
    "\n",
    "sorted(total, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elephant Conclusion\n",
    "Inception may be a viable model for classifying Elephants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rhinos\n",
    "results = {}\n",
    "\n",
    "# Classification is slow, short-circuit\n",
    "result_cache  = \"rhino-classifications.npy\"\n",
    "\n",
    "keep = np.random.choice((True,False), size=len(img_rhinos), replace=True, p=(1, 0))\n",
    "kept_rhinos = np.array(img_rhinos)[keep]\n",
    "\n",
    "if os.path.exists(DATA_DIR + '/' + result_cache):\n",
    "    results = np.load(DATA_DIR + '/' + result_cache).item()\n",
    "    print(\"Read cache from %s\" % (DATA_DIR + '/' + result_cache))\n",
    "else:\n",
    "    for i in range(len(kept_rhinos)):\n",
    "        img = kept_rhinos[i]\n",
    "        sys.stdout.write(\"\\r[%i%% DONE] Classifying %i of %i, img %s \" % (i/len(kept_rhinos)*100 ,i, len(kept_rhinos), img))\n",
    "        sys.stdout.flush()\n",
    "        result = run_inference_on_image(img)\n",
    "        for r in result:\n",
    "            typ, id, score = r\n",
    "            if typ not in results:\n",
    "                results[typ] = []\n",
    "            results[typ].append(score)\n",
    "\n",
    "    np.save(DATA_DIR + '/' + result_cache, results)\n",
    "    sys.stdout.write(\"\\r[100%% DONE] All Images Classified, results saved to %s\" % (DATA_DIR + '/' + result_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top classes classified by median\n",
    "\n",
    "all_classes = []\n",
    "\n",
    "for key in results.keys():\n",
    "    median = np.median(results[key])\n",
    "    all_classes.append((key, median))\n",
    "\n",
    "sorted(all_classes, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhino Conclusion\n",
    "\n",
    "Note, Rhino isn't present in ANY f the classifications done by the Inception based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100% DONE] All Images Classified, results saved to /vagrant/data/tapir-classifications.npy).JPG  min depois (21).JPG "
     ]
    }
   ],
   "source": [
    "# Tapirs\n",
    "results = {}\n",
    "\n",
    "# Classification is slow, short-circuit\n",
    "result_cache  = \"tapir-classifications.npy\"\n",
    "\n",
    "keep = np.random.choice((True,False), size=len(img_tapir), replace=True, p=(0.05, 0.95))\n",
    "kept_tapir = np.array(img_tapir)[keep]\n",
    "\n",
    "if os.path.exists(DATA_DIR + '/' + result_cache):\n",
    "    results = np.load(DATA_DIR + '/' + result_cache).item()\n",
    "    print(\"Read cache from %s\" % (DATA_DIR + '/' + result_cache))\n",
    "else:\n",
    "    for i in range(len(kept_tapir)):\n",
    "        img = kept_tapir[i]\n",
    "        sys.stdout.write(\"\\r[%i%% DONE] Classifying %i of %i, img %s \" % (i/len(kept_tapir)*100 ,i, len(kept_tapir), img))\n",
    "        sys.stdout.flush()\n",
    "        result = run_inference_on_image(img)\n",
    "        for r in result:\n",
    "            typ, id, score = r\n",
    "            if typ not in results:\n",
    "                results[typ] = []\n",
    "            results[typ].append(score)\n",
    "\n",
    "    np.save(DATA_DIR + '/' + result_cache, results)\n",
    "    sys.stdout.write(\"\\r[100%% DONE] All Images Classified, results saved to %s\" % (DATA_DIR + '/' + result_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wild boar, boar, Sus scrofa', 26),\n",
       " ('grey fox, gray fox, Urocyon cinereoargenteus', 25),\n",
       " ('hog, pig, grunter, squealer, Sus scrofa', 25),\n",
       " ('armadillo', 24),\n",
       " ('tusker', 19),\n",
       " ('barn', 19),\n",
       " ('window screen', 18),\n",
       " ('monitor', 16),\n",
       " ('park bench', 11),\n",
       " ('screen, CRT screen', 10),\n",
       " ('Indian elephant, Elephas maximus', 10),\n",
       " ('hippopotamus, hippo, river horse, Hippopotamus amphibius', 10),\n",
       " ('warthog', 10),\n",
       " ('Arctic fox, white fox, Alopex lagopus', 8),\n",
       " ('white wolf, Arctic wolf, Canis lupus tundrarum', 7),\n",
       " ('dugong, Dugong dugon', 6),\n",
       " ('red wolf, maned wolf, Canis rufus, Canis niger', 6),\n",
       " ('television, television system', 6),\n",
       " ('web site, website, internet site, site', 6),\n",
       " ('water buffalo, water ox, Asiatic buffalo, Bubalus bubalis', 5),\n",
       " ('stingray', 5),\n",
       " ('wombat', 5),\n",
       " ('dhole, Cuon alpinus', 5),\n",
       " ('electric ray, crampfish, numbfish, torpedo', 5),\n",
       " ('timber wolf, grey wolf, gray wolf, Canis lupus', 5),\n",
       " ('piggy bank, penny bank', 4),\n",
       " ('American black bear, black bear, Ursus americanus, Euarctos americanus', 3),\n",
       " ('skunk, polecat, wood pussy', 3),\n",
       " ('groenendael', 3),\n",
       " ('ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus', 3),\n",
       " ('African elephant, Loxodonta africana', 3),\n",
       " ('hammerhead, hammerhead shark', 2),\n",
       " ('platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus',\n",
       "  2),\n",
       " ('viaduct', 2),\n",
       " ('ox', 2),\n",
       " ('fountain', 2),\n",
       " ('coral reef', 2),\n",
       " ('Scottish deerhound, deerhound', 2),\n",
       " ('badger', 2),\n",
       " ('hyena, hyaena', 2),\n",
       " ('planetarium', 1),\n",
       " ('Irish wolfhound', 1),\n",
       " ('quail', 1),\n",
       " ('red fox, Vulpes vulpes', 1),\n",
       " ('Great Dane', 1),\n",
       " ('Weimaraner', 1),\n",
       " ('mouse, computer mouse', 1),\n",
       " ('hamster', 1),\n",
       " ('baboon', 1),\n",
       " ('lighter, light, igniter, ignitor', 1),\n",
       " ('brown bear, bruin, Ursus arctos', 1),\n",
       " ('Samoyed, Samoyede', 1),\n",
       " ('hay', 1),\n",
       " ('coyote, prairie wolf, brush wolf, Canis latrans', 1),\n",
       " ('syringe', 1),\n",
       " ('butternut squash', 1),\n",
       " ('bubble', 1),\n",
       " ('tiger shark, Galeocerdo cuvieri', 1),\n",
       " ('sloth bear, Melursus ursinus, Ursus ursinus', 1),\n",
       " ('gorilla, Gorilla gorilla', 1),\n",
       " ('wallaby, brush kangaroo', 1),\n",
       " ('Band Aid', 1),\n",
       " ('sturgeon', 1),\n",
       " ('book jacket, dust cover, dust jacket, dust wrapper', 1),\n",
       " ('bathing cap, swimming cap', 1),\n",
       " ('wok', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the top classes classified by total images classified\n",
    "\n",
    "total = []\n",
    "\n",
    "for key in results.keys():\n",
    "    m = len(results[key])\n",
    "    total.append((key, m))\n",
    "\n",
    "sorted(total, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tapir Conclusion\n",
    "Tapirs aren't classified at all by the Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_is_elephant(img, threshold):\n",
    "    is_elephant = run_elephant_inference(img)\n",
    "    return True if is_elephant >= threshold else False\n",
    "    \n",
    "# Test set of known elephants\n",
    "imgs = np.array(img_elephants)\n",
    "is_test = np.random.choice((True,False), size=len(img_elephants), replace=True, p=(0.01, 0.99))\n",
    "\n",
    "a = []\n",
    "i = 0\n",
    "for img in imgs[is_test]:\n",
    "    i += 1\n",
    "    sys.stdout.write(\"\\rClassifying %i of %i, img %s \" % (i, len(imgs[is_test]), img))\n",
    "    a.append(img_is_elephant(img, ELEPHANT_THRESHOLD))\n",
    "\n",
    "test_true = np.array([a, [True] * len(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run classification on snapshot negative data set\n",
    "# The original any included elephants and excluded empty shots\n",
    "# Any2 excludes elephants and has empty scenes\n",
    "any_dir = DATA_DIR + '/snapshot/Any2'\n",
    "img_any = [os.path.join(any_dir, img) for img in os.listdir(any_dir)]\n",
    "\n",
    "any_imgs = np.random.randint(0, len(img_any), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(img_any[any_imgs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_test = np.random.choice((True,False), size=len(img_elephants), replace=True, p=(0.01, 0.99))\n",
    "\n",
    "result = []\n",
    "for i in range(len(imgs[is_test])):\n",
    "    img = imgs[i]\n",
    "    sys.stdout.write(\"\\rClassifying %i of %i, img %s \" % (i, len(imgs[is_test]), img))\n",
    "    result.append(img_is_elephant(img, ELEPHANT_THRESHOLD))\n",
    "    \n",
    "test_false = np.array([result, [False] * len(result)])\n",
    "sys.stdout.write(\"\\r DONE classifying %i images\" % (len(imgs[is_test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(test_results):\n",
    "    true_pos = np.where(test_true[0] == True)[0].shape[0]\n",
    "    false_pos = np.where(test_false[0] == True)[0].shape[0]\n",
    "    true_neg = np.where(test_false[0] == False)[0].shape[0]\n",
    "    false_neg = np.where(test_true[0] == False)[0].shape[0]\n",
    "\n",
    "    return (true_pos, false_pos, true_neg, false_neg)\n",
    "\n",
    "def precision(true_pos, false_pos, true_neg, false_neg): \n",
    "    return true_pos / (true_pos + false_pos)\n",
    "    \n",
    "def recall(true_pos, false_pos, true_neg, false_neg):\n",
    "    return true_pos / (true_pos + false_neg)\n",
    "    \n",
    "    \n",
    "\n",
    "test_results = np.concatenate((test_true.T, test_false.T))\n",
    "conf_matr = confusion_matrix(test_results)\n",
    "\n",
    "print(conf_matr)\n",
    "print(\"Inception Classifier has %f precision and %f recall\" % (precision(*conf_matr), recall(*conf_matr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anaylze PR Curve for given thresholds\n",
    "### Score Inception Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Classify Elephants\n",
    "\n",
    "# Create a single list of data, with img location and known label\n",
    "\n",
    "def sample_and_label(img_list, prob, label):\n",
    "    imgs = np.array(img_list)\n",
    "    keep = np.random.choice((True,False), size=len(img_list), replace=True, p=prob)\n",
    "    return label_data(imgs[keep], label)\n",
    "\n",
    "def label_data(source_data, label):\n",
    "    sample_size = len(source_data)\n",
    "    known_labels = np.array([label] * sample_size).reshape(sample_size, 1)\n",
    "    known_images = source_data.reshape(sample_size,1)\n",
    "    labeled_data = np.hstack((known_images, known_labels))\n",
    "    return labeled_data\n",
    "\n",
    "# Load data sources\n",
    "elephant_dir = DATA_DIR + '/snapshot/Elephant'\n",
    "any_dir = DATA_DIR + '/snapshot/Any2'\n",
    "\n",
    "img_any = [os.path.join(any_dir, img) for img in os.listdir(any_dir)]\n",
    "img_elephants = [os.path.join(elephant_dir, img) for img in os.listdir(elephant_dir)]\n",
    "\n",
    "# Create a stream of labeled data for elephants\n",
    "pos_labeled_data = sample_and_label(img_elephants, prob=(0.04, 0.96), label=True)\n",
    "neg_labeled_data = sample_and_label(img_any, prob=(0.01, 0.99), label=False)\n",
    "labeled_data = np.vstack((pos_labeled_data, neg_labeled_data))\n",
    "\n",
    "i = 0\n",
    "rows, col = labeled_data.shape\n",
    "inception_elephant_score = []\n",
    "for labeled in labeled_data:\n",
    "    i += 1\n",
    "    img, label = labeled\n",
    "    sys.stdout.write(\"\\rClassifying %i of %i, img %s\" % (i, rows, img))\n",
    "    pred = run_elephant_inference(img)\n",
    "    inception_elephant_score.append(pred)\n",
    "\n",
    "    \n",
    "sys.stdout.write(\"\\rDONE classifying images                                                                      \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Classify Rhinos\n",
    "\n",
    "\n",
    "# Load data sources\n",
    "rhino_dir = DATA_DIR + '/snapshot/Rhino'\n",
    "any_dir = DATA_DIR + '/snapshot/Any2'\n",
    "\n",
    "img_any = [os.path.join(any_dir, img) for img in os.listdir(any_dir)]\n",
    "img_rhino = [os.path.join(rhino_dir, img) for img in os.listdir(rhino_dir)]\n",
    "\n",
    "# Create a stream of labeled data for rhinos\n",
    "pos_labeled_data = sample_and_label(img_rhino, prob=(0.04, 0.96), label=True)\n",
    "neg_labeled_data = sample_and_label(img_any, prob=(0.01, 0.99), label=False)\n",
    "labeled_data = np.vstack((pos_labeled_data, neg_labeled_data))\n",
    "\n",
    "i = 0\n",
    "rows, col = labeled_data.shape\n",
    "inception_rhino_score = []\n",
    "for labeled in labeled_data:\n",
    "    i += 1\n",
    "    img, label = labeled\n",
    "    sys.stdout.write(\"\\rClassifying %i of %i, img %s\" % (i, rows, img))\n",
    "    pred = run_rhino_inference(img)\n",
    "    inception_rhino_score.append(pred)\n",
    "    \n",
    "sys.stdout.write(\"\\rDONE classifying images                                                                  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision recall curve\n",
    "labeled_data[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(labeled_data[:,1], inception_elephant_score, pos_label='True')\n",
    "\n",
    "plt.plot(precision, recall)\n",
    "plt.xlabel(\"precision\")\n",
    "plt.ylabel(\"recall\")\n",
    "plt.title(\"PR Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fscore\n",
    "fscore = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "plt.plot(recall, fscore)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.title(\"Fscore against recall\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fscore\n",
    "fscore = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"precision\")\n",
    "plt.ylabel(\"f1 score\")\n",
    "plt.title(\"Fscore against precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(labeled_data[:,1], inception_elephant_score, pos_label='True')\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_precision = precision[:len(thresholds)]\n",
    "real_recall = recall[:len(thresholds)]\n",
    "real_fscore = fscore[:len(thresholds)]\n",
    "\n",
    "plt.plot(thresholds, real_precision)\n",
    "plt.plot(thresholds, real_recall)\n",
    "plt.plot(thresholds, real_fscore)\n",
    "plt.legend(['precision', 'recall', 'fscore'])\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Annoyingly, roc_auc_score doesn't allow you to have arbitrary labels\n",
    "# map into binary\n",
    "def binarize(x):\n",
    "    if(x == 'True'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "vfunc = np.vectorize(binarize)\n",
    "\n",
    "labels = labeled_data[:,1]\n",
    "labels = vfunc(labels)\n",
    "\n",
    "auc = roc_auc_score(labels, inception_elephant_score)\n",
    "print(\"Inception based model AUC: %f\" % (auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO NEXT STEPS\n",
    "# Extract this so that analysis can be re-run with a single command for future models\n",
    "# Begin learning how to do transfer learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
